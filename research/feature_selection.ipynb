{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\harik\\\\OneDrive\\\\Desktop\\\\HARIKRISHNAN_DETAILS\\\\Real_Estate_Predictor_Web_App\\\\Real_Estate_Price_Predictor_Web_App\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\harik\\\\OneDrive\\\\Desktop\\\\HARIKRISHNAN_DETAILS\\\\Real_Estate_Predictor_Web_App\\\\Real_Estate_Price_Predictor_Web_App'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureSelectionConfig:\n",
    "    root_dir:Path\n",
    "    transformed_data_file:Path\n",
    "    X_train_data_file:Path\n",
    "    X_test_data_file:Path\n",
    "    Y_train_data_file:Path\n",
    "    Y_test_data_file:Path\n",
    "    params_target_label:str\n",
    "    params_Id_column: list\n",
    "    params_alpha_for_lasso: int\n",
    "    params_random_state_for_lasso:int\n",
    "    params_percentile_for_mutual_info:int\n",
    "    params_test_size:int\n",
    "    params_random_state_for_train_test_split:int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureScalingConfig:\n",
    "    root_dir:Path\n",
    "    X_train_data_file:Path\n",
    "    X_test_data_file:Path\n",
    "    X_train_scaled_data_file:Path\n",
    "    X_test_scaled_data_file:Path\n",
    "    feature_scaling_model:Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_estate_price_predictor.constants import *\n",
    "from real_estate_price_predictor.utils.common import read_yaml, create_directories, save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_feature_selection(self) -> FeatureSelectionConfig:\n",
    "        config = self.config.feature_selection\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        feature_selection_config = FeatureSelectionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            transformed_data_file = config.transformed_data_file,\n",
    "            X_train_data_file = config.X_train_data_file,\n",
    "            X_test_data_file =  config.X_test_data_file,\n",
    "            Y_train_data_file= config.Y_train_data_file,\n",
    "            Y_test_data_file = config.Y_test_data_file,\n",
    "            params_target_label = self.params.target_label,\n",
    "            params_Id_column = self.params.Id_column,\n",
    "            params_alpha_for_lasso = self.params.alpha_for_lasso,\n",
    "            params_random_state_for_lasso = self.params.random_state_for_lasso,\n",
    "            params_percentile_for_mutual_info = self.params.percentile_for_mutual_info,\n",
    "            params_test_size = self.params.test_size,\n",
    "            params_random_state_for_train_test_split = self.params.random_state_for_train_test_split\n",
    "            \n",
    "        )\n",
    "\n",
    "        return feature_selection_config\n",
    "    \n",
    "    def get_feature_scaling(self) -> FeatureScalingConfig:\n",
    "        config = self.config.feature_scaling\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        feature_scaling_config = FeatureScalingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            X_train_data_file = config.X_train_data_file,\n",
    "            X_test_data_file = config.X_test_data_file,\n",
    "            X_train_scaled_data_file = config.X_train_scaled_data_file,\n",
    "            X_test_scaled_data_file =  config.X_test_scaled_data_file,\n",
    "            feature_scaling_model = config.feature_scaling_model\n",
    "        )\n",
    "\n",
    "        return feature_scaling_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from real_estate_price_predictor import logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionAndTrainTestSplit:\n",
    "    \n",
    "    def __init__(self,config=FeatureSelectionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def lasso_feature_selection(self):\n",
    "        if os.path.exists(self.config.transformed_data_file):\n",
    "            dataset = pd.read_csv(self.config.transformed_data_file)\n",
    "            X = dataset.drop([self.config.params_Id_column[0],self.config.params_target_label,],axis=1)\n",
    "            Y = dataset[[self.config.params_target_label]]\n",
    "            feature_sel_model = SelectFromModel(Lasso(alpha=self.config.params_alpha_for_lasso, random_state=self.config.params_random_state_for_lasso)) # remember to set the seed, the random state in this function\n",
    "            feature_sel_model.fit(X, Y)\n",
    "            selected_feat = X.columns[(feature_sel_model.get_support())]\n",
    "            return X[selected_feat]\n",
    "        else: logger.info(f\">>>>>> transformation data file is not present <<<<<<\")\n",
    "        \n",
    "    \n",
    "    def mutual_information_feature_selection(self):\n",
    "        if os.path.exists(self.config.transformed_data_file):\n",
    "            dataset = pd.read_csv(self.config.transformed_data_file)\n",
    "            X = dataset.drop([self.config.params_Id_column[0],self.config.params_target_label],axis=1)\n",
    "            Y = dataset[[self.config.params_target_label]]\n",
    "            selected_top_columns = SelectPercentile(mutual_info_regression, percentile=20)\n",
    "            selected_top_columns.fit(X, Y)\n",
    "            selected_feature = X.columns[selected_top_columns.get_support()]\n",
    "            return X[selected_feature]\n",
    "        else: logger.info(f\">>>>>> transformation data file is not present <<<<<<\")\n",
    "\n",
    "    def test_train_split(self,dataset:pd.DataFrame):\n",
    "        X = dataset\n",
    "        if os.path.exists(self.config.transformed_data_file):\n",
    "            dataset = pd.read_csv(self.config.transformed_data_file)\n",
    "            Y = dataset[[self.config.params_target_label]]\n",
    "            X_train,X_test,y_train,y_test =train_test_split(X,Y,test_size=self.config.params_test_size,random_state=self.config.params_random_state_for_train_test_split)\n",
    "            X_train = pd.DataFrame(X_train,columns=X.columns)\n",
    "            X_test = pd.DataFrame(X_test,columns=X.columns)\n",
    "            X_train.to_csv(self.config.X_train_data_file,index=False)\n",
    "            X_test.to_csv(self.config.X_test_data_file,index=False)\n",
    "            y_train = pd.DataFrame(y_train,columns=Y.columns)\n",
    "            y_test = pd.DataFrame(y_test,columns=Y.columns)\n",
    "            y_train.to_csv(self.config.Y_train_data_file,index=False)\n",
    "            y_test.to_csv(self.config.Y_test_data_file,index=False)\n",
    "        else: logger.info(f\">>>>>> transformation data file is not present <<<<<<\")\n",
    "\n",
    "class FeatureScaling():\n",
    "    def __init__(self,config = FeatureScalingConfig):\n",
    "        self.config =  config\n",
    "    \n",
    "    def read_csv_file(self,path:Path):\n",
    "        dataset = pd.read_csv(path)\n",
    "        return dataset \n",
    "    \n",
    "    def min_max_scaler(self):\n",
    "        X_train = self.read_csv_file(self.config.X_train_data_file)\n",
    "        X_test = self.read_csv_file(self.config.X_test_data_file)\n",
    "        scaler=MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        if (os.path.exists(self.config.X_train_data_file)) and (os.path.exists(self.config.X_test_data_file) ):\n",
    "            X_train_data = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "            X_test_data = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "            X_train_data.to_csv(self.config.X_train_scaled_data_file,index=False)\n",
    "            X_test_data.to_csv(self.config.X_test_scaled_data_file,index=False)\n",
    "            save_object(self.config.feature_scaling_model,scaler)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    feature_selection_config = config.get_feature_selection()\n",
    "    feature_selection = FeatureSelectionAndTrainTestSplit(config=feature_selection_config)\n",
    "    dataset = feature_selection.lasso_feature_selection()\n",
    "    print(dataset.columns)\n",
    "    print(len(dataset.columns))\n",
    "    feature_selection.test_train_split(dataset)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-06 16:15:30,457: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-10-06 16:15:30,467: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-10-06 16:15:30,469: INFO: common: created directory at: artifacts]\n",
      "[2024-10-06 16:15:30,471: INFO: common: created directory at: artifacts/train_test_data_scaled]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    feature_scaling_config = config.get_feature_scaling()\n",
    "    feature_scaling = FeatureScaling(config=feature_scaling_config)\n",
    "    feature_scaling.min_max_scaler()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame()\n",
    "print(empty_df.isnull().all().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# X_train = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data\\X_train.csv')\n",
    "# X_test = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data\\X_test.csv')\n",
    "# y_train = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data\\Y_train.csv')\n",
    "# y_test = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data\\Y_test.csv')\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train_data = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "# X_test_data = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# if dataset.isnull().all().all():\n",
    "# else: \n",
    "            # dataframe = pd.DataFrame(scaler.transform(dataset), columns=dataset.columns)\n",
    "            # return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data_scaled\\X_test_scaled.csv')\n",
    "X_train_data  = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data_scaled\\X_train_scaled.csv')\n",
    "y_train = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data\\Y_train.csv')\n",
    "y_test = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data\\Y_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_data.shape\n",
    "X_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8915319920524694, 0.8890182559450005, 0.8094233922369707, 0.8805981099194473, 0.8930781403609384, 0.7496123295499891, 0.7908597767658794, 0.8849228501059885, 0.8649128675460815]\n",
      "[0.8710831053082628, 0.8680954681313531, 0.7734950153636126, 0.858087917527212, 0.8729207405929185, 0.7024080965962985, 0.751431701893873, 0.8632279775849863, 0.8394456212637854]\n",
      "[0.014852771905645039, 0.015196983528423988, 0.026096089890625635, 0.01634997334262119, 0.01464105428869481, 0.03428615522264225, 0.02863804812839099, 0.01575777679769206, 0.018497792256235945]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "list_of_models = ['Linear Regression', 'Ridge Regression', 'Polynomial Regression', 'SVR', 'Random Forrest Regressor', 'Decision Tree Regressor','AdaBoost Regressor','Gradient Boosting Regressor','XGBRegressor' ]\n",
    "r2_score_of_models=[]\n",
    "adjusted_r2_score =[]\n",
    "mse=[]\n",
    "for i  in list_of_models:\n",
    "    if i == 'Linear Regression':\n",
    "        model = LinearRegression()\n",
    "    elif i == 'Ridge Regression':\n",
    "        model = Ridge()\n",
    "    elif i == 'Polynomial Regression':\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear_model', LinearRegression())])\n",
    "    elif i == 'SVR':\n",
    "        model = SVR(kernel='rbf', C=1.0)\n",
    "    elif i == 'Random Forrest Regressor':\n",
    "        model = RandomForestRegressor(n_estimators=100)\n",
    "    elif i == 'AdaBoost Regressor':\n",
    "        model = AdaBoostRegressor()\n",
    "    elif i == 'Gradient Boosting Regressor':\n",
    "        model = GradientBoostingRegressor()\n",
    "    elif i == 'XGBRegressor':\n",
    "        model = XGBRegressor()\n",
    "    else:\n",
    "        model = DecisionTreeRegressor(max_depth=5)\n",
    "# Train the model on the training data\n",
    "\n",
    "    model.fit(X_train_data, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "\n",
    "    y_pred = model.predict(X_test_data)\n",
    "\n",
    "# Evaluate the model performance (e.g., R-squared, Mean Squared Error)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_score_of_models.append(r2)\n",
    "\n",
    "# Calculate the adjusted R²\n",
    "\n",
    "    n = X_test_data.shape[0]  # Number of observations (samples) in the testing set\n",
    "    p = X_test_data.shape[1]  # Number of features in the model\n",
    "    adjusted_r2_score.append(1 - (1 - r2) * (n - 1) / (n - p - 1))\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score_of_models)\n",
    "print(adjusted_r2_score)\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Adjusted_R2_Score</th>\n",
       "      <th>R2_Score</th>\n",
       "      <th>Mean_Squared_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.871083</td>\n",
       "      <td>0.891532</td>\n",
       "      <td>0.014853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>0.889018</td>\n",
       "      <td>0.015197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>0.773495</td>\n",
       "      <td>0.809423</td>\n",
       "      <td>0.026096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.858088</td>\n",
       "      <td>0.880598</td>\n",
       "      <td>0.016350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forrest Regressor</td>\n",
       "      <td>0.872921</td>\n",
       "      <td>0.893078</td>\n",
       "      <td>0.014641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.702408</td>\n",
       "      <td>0.749612</td>\n",
       "      <td>0.034286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.751432</td>\n",
       "      <td>0.790860</td>\n",
       "      <td>0.028638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.863228</td>\n",
       "      <td>0.884923</td>\n",
       "      <td>0.015758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.839446</td>\n",
       "      <td>0.864913</td>\n",
       "      <td>0.018498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Models  Adjusted_R2_Score  R2_Score  \\\n",
       "0            Linear Regression           0.871083  0.891532   \n",
       "1             Ridge Regression           0.868095  0.889018   \n",
       "2        Polynomial Regression           0.773495  0.809423   \n",
       "3                          SVR           0.858088  0.880598   \n",
       "4     Random Forrest Regressor           0.872921  0.893078   \n",
       "5      Decision Tree Regressor           0.702408  0.749612   \n",
       "6           AdaBoost Regressor           0.751432  0.790860   \n",
       "7  Gradient Boosting Regressor           0.863228  0.884923   \n",
       "8                 XGBRegressor           0.839446  0.864913   \n",
       "\n",
       "   Mean_Squared_Error  \n",
       "0            0.014853  \n",
       "1            0.015197  \n",
       "2            0.026096  \n",
       "3            0.016350  \n",
       "4            0.014641  \n",
       "5            0.034286  \n",
       "6            0.028638  \n",
       "7            0.015758  \n",
       "8            0.018498  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Models': list_of_models, 'Adjusted_R2_Score': adjusted_r2_score, 'R2_Score': r2_score_of_models , 'Mean_Squared_Error': mse}\n",
    "performance_metrics = pd.DataFrame.from_dict(data)\n",
    "performance_metrics.set_index('Models', inplace = False)\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
