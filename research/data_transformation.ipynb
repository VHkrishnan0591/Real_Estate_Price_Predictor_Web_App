{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\harik\\\\OneDrive\\\\Desktop\\\\HARIKRISHNAN_DETAILS\\\\Real_Estate_Predictor_Web_App\\\\Real_Estate_Price_Predictor_Web_App'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir:Path\n",
    "    data_file:Path\n",
    "    transformed_data:Path\n",
    "    params_discrete_feature: list\n",
    "    params_Id_column: list\n",
    "    params_categorical_stratergy:str\n",
    "    params_numerical_stratergy:str\n",
    "    params_fill_value:str\n",
    "    params_target_label:str\n",
    "    params_rare_categorical_variable:str\n",
    "    params_ordinal_categorical_feature:list\n",
    "    params_nominal_categorical_feature:list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_estate_price_predictor.constants import *\n",
    "from real_estate_price_predictor.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_file = config.data_file,\n",
    "            transformed_data = config.transformed_data_file,\n",
    "            params_discrete_feature = self.params.discrete_feature,\n",
    "            params_Id_column = self.params.Id_column,\n",
    "            params_categorical_stratergy = self.params.categorical_stratergy,\n",
    "            params_numerical_stratergy = self.params.numerical_stratergy,\n",
    "            params_fill_value = self.params.fill_value,\n",
    "            params_target_label = self.params.target_label,\n",
    "            params_rare_categorical_variable = self.params.rare_categorical_variable,\n",
    "            params_ordinal_categorical_feature = self.params.ordinal_categorical_feature,\n",
    "            params_nominal_categorical_feature = self.params.nominal_categorical_feature\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparatingDifferentFeatures:\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def read_data(self):\n",
    "        dataset = pd.read_csv(self.config.data_file)\n",
    "        return dataset\n",
    "\n",
    "# Features with null values\n",
    "\n",
    "    def features_with_null_values(self, df:pd.DataFrame):\n",
    "        dataset = df\n",
    "        features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n",
    "        return features_with_na\n",
    "    \n",
    "# Finding both numerical and categorical features with null values\n",
    "\n",
    "    def num_and_categorical_features_with_na(self,df:pd.DataFrame, categorical:bool):\n",
    "        numerical_features_with_na =[]\n",
    "        categorical_features_with_na =[]\n",
    "        features_with_na = self.features_with_null_values(df)\n",
    "        for feature in features_with_na:\n",
    "            if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "                numerical_features_with_na.append(feature)\n",
    "            else:\n",
    "                categorical_features_with_na.append(feature)\n",
    "        if categorical:\n",
    "            return categorical_features_with_na\n",
    "        else: \n",
    "            return numerical_features_with_na\n",
    "    \n",
    "# Finding all the numerical features\n",
    "\n",
    "    def total_numerical_features(self,dataset:pd.DataFrame):\n",
    "        numerical_features = []\n",
    "        for feature in dataset.columns:\n",
    "            if dataset[feature].dtypes != 'O':\n",
    "                numerical_features.append(feature)\n",
    "        return numerical_features\n",
    "\n",
    "# Finding year or datatime variable\n",
    "\n",
    "    def finding_year_feature(self,dataset:pd.DataFrame):\n",
    "        year_feature = []\n",
    "        numerical_features = self.total_numerical_features(dataset)\n",
    "        for feature in numerical_features:\n",
    "            if 'Yr' in feature or 'Year' in feature:\n",
    "                year_feature.append(feature)\n",
    "        return year_feature\n",
    "        \n",
    "# Finding Continuous Variable\n",
    "\n",
    "    def continous_variables(self,df:pd.DataFrame):\n",
    "        continuous_feature=[]\n",
    "        numerical_features = self.total_numerical_features(df) \n",
    "        year_feature = self.finding_year_feature(df)\n",
    "        for feature in numerical_features:\n",
    "            if feature not in self.config.params_discrete_feature+year_feature+self.config.params_Id_column:\n",
    "                continuous_feature.append(feature)\n",
    "        return continuous_feature\n",
    "\n",
    "# Replacing the zeros with 1 to perform log transform\n",
    "\n",
    "    def replacing_zeros_of_continuous_features(self,dataset:pd.DataFrame):\n",
    "        continuous_feature = self.continous_variables(dataset)\n",
    "        for feature in continuous_feature:\n",
    "            dataset.loc[dataset[feature] == 0, feature] = 1\n",
    "        return dataset\n",
    "\n",
    "# Finding the categorical features\n",
    "\n",
    "    def total_categorical_features(self,dataset:pd.DataFrame):\n",
    "        return [feature for feature in dataset.columns if dataset[feature].dtypes=='O']\n",
    "\n",
    "# Handling Missing Values by creating a new category for categroical and with median for numerical\n",
    "\n",
    "    def filling_missing_values(self, dataset:pd.DataFrame):\n",
    "        categorical_imputer = SimpleImputer(strategy= self.config.params_categorical_stratergy,fill_value=self.config.params_fill_value)\n",
    "        numerical_imputer = SimpleImputer(strategy=self.config.params_numerical_stratergy)\n",
    "        categorical_features = self.total_categorical_features(dataset)\n",
    "        numerical_features = self.total_numerical_features(dataset)\n",
    "        dataset[categorical_features] = categorical_imputer.fit_transform(dataset[categorical_features])\n",
    "        dataset[numerical_features] = numerical_imputer.fit_transform(dataset[numerical_features])\n",
    "        return dataset\n",
    "    \n",
    "# Saving the transformed data\n",
    "\n",
    "    def save_the_transformed_data(self,dataset:pd.DataFrame):\n",
    "        dataset.to_csv(self.config.transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_date_time_variables(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs \n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "         year_features = self.finding_year_feature(X)\n",
    "         for feature in year_features:\n",
    "             if feature != 'YrSold':\n",
    "                 X[feature]=X['YrSold']-X[feature]\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_transform_of_numeric_variables(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self, config:DataTransformationConfig): # no *args or **kargs\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "         continous_features = self.continous_variables(X)\n",
    "         X = self.replacing_zeros_of_continuous_features(X)\n",
    "         for feature in continous_features:\n",
    "             X[feature]=np.log(X[feature])\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_rare_categorical_values(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "         categorical_features = self.total_categorical_features(X)\n",
    "         for feature in categorical_features:\n",
    "             temp=X.groupby(feature)[self.config.params_target_label].count()/len(X)\n",
    "             temp_df=temp[temp>0.01].index\n",
    "             X[feature]=np.where(X[feature].isin(temp_df),X[feature],self.config.params_rare_categorical_variable)\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_ordinal_categorical_values(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs\n",
    "         self.label_ordered_feature ={}\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         for feature in self.config.params_ordinal_categorical_feature:\n",
    "             labels_ordered=X.groupby([feature])[self.config.params_target_label].mean().sort_values().index\n",
    "             labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n",
    "             self.label_ordered_feature[feature] = labels_ordered\n",
    "         return self\n",
    "    def transform(self, X, y=None):\n",
    "         for feature in self.config.params_ordinal_categorical_feature:\n",
    "           X[feature]=X[feature].map(self.label_ordered_feature[feature])\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_nominal_categorical_values(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs\n",
    "         self.label_nominal_feature ={}\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         for feature in self.config.params_nominal_categorical_feature:\n",
    "             nominal_label=X.groupby([feature])[self.config.params_target_label].mean().to_dict()\n",
    "             self.label_nominal_feature[feature] = nominal_label\n",
    "         return self\n",
    "    def transform(self, X, y=None):\n",
    "         for feature in self.config.params_nominal_categorical_feature:\n",
    "           X[feature]=X[feature].map(self.label_nominal_feature[feature])\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_outliers_for_continous_variable(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.iqr_boundaries_conitnous_feature ={}\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        continuous_feature = self.continous_variables(X)\n",
    "        for feature in continuous_feature:\n",
    "            IQR=X[feature].quantile(0.75)-X[feature].quantile(0.25)\n",
    "            lower_bridge=X[feature].quantile(0.25)-(IQR*3)\n",
    "            upper_bridge=X[feature].quantile(0.75)+(IQR*3)\n",
    "            self.iqr_boundaries_conitnous_feature[feature] = [lower_bridge,upper_bridge]\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        continuous_feature = self.continous_variables(X)\n",
    "        for feature in continuous_feature:\n",
    "            lower_bridge, upper_bridge = self.iqr_boundaries_conitnous_feature[feature]\n",
    "            X.loc[X[feature]<=lower_bridge,feature]=lower_bridge\n",
    "            X.loc[X[feature]>=upper_bridge,feature]=upper_bridge\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = SeparatingDifferentFeatures(config=data_transformation_config)\n",
    "\n",
    "    # Read the data\n",
    "\n",
    "    dataset = data_transformation.read_data()\n",
    "\n",
    "    # Handling Null Values\n",
    "\n",
    "    dataset = data_transformation.filling_missing_values(dataset)\n",
    "\n",
    "    # Handling date time variables\n",
    "\n",
    "    date_time_variables = handling_date_time_variables(config=data_transformation_config)\n",
    "    dataset = date_time_variables.transform(dataset)\n",
    "\n",
    "    # Transforming the continous variables using logrithmic transform\n",
    "\n",
    "    log_transform = log_transform_of_numeric_variables(config=data_transformation_config)\n",
    "    dataset = log_transform.transform(dataset)\n",
    "\n",
    "    # Handling rare categorical variable\n",
    "\n",
    "    rare_categorical_values = handling_rare_categorical_values(config=data_transformation_config)\n",
    "    dataset = rare_categorical_values.transform(dataset)    \n",
    "\n",
    "    # Encoding the ordinal categorical features using (Target Guided Encoding)\n",
    "\n",
    "    ordinal_features = handling_ordinal_categorical_values(config=data_transformation_config)\n",
    "    ordinal_features.fit(dataset)\n",
    "    dataset = ordinal_features.transform(dataset)\n",
    "\n",
    "    # Encoding the nominal categorical features using (Mean Encoding)\n",
    "\n",
    "    nominal_features = handling_nominal_categorical_values(config=data_transformation_config)\n",
    "    nominal_features.fit(dataset)\n",
    "    dataset = nominal_features.transform(dataset)    \n",
    "\n",
    "    # Removing the Outliers in Continous feature\n",
    "\n",
    "    Removal_of_outlier = handling_outliers_for_continous_variable(config=data_transformation_config)\n",
    "    Removal_of_outlier.fit(dataset)\n",
    "    dataset = Removal_of_outlier.transform(dataset)\n",
    "\n",
    "    # Saving the transformed data\n",
    "\n",
    "    data_transformation.save_the_transformed_data(dataset)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigurationManager()\n",
    "data_transformation_config = config.get_data_transformation_config()\n",
    "data_transformation = SeparatingDifferentFeatures(config=data_transformation_config)\n",
    "dataset = data_transformation.read_data()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_with_na = data_transformation.num_and_categorical_features_with_na(dataset,True)\n",
    "numerical_features_with_na = data_transformation.num_and_categorical_features_with_na(dataset,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The categrical null count is \",len(categorical_features_with_na))\n",
    "print(\"The numerical null count is \",len(numerical_features_with_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data_transformation.total_numerical_features(dataset)\n",
    "print('Number of numerical variables: ', len(numerical_features))\n",
    "dataset[numerical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature = data_transformation.continous_variables(dataset)\n",
    "print(\"Continuous feature Count {}\".format(len(continuous_feature)))\n",
    "dataset[continuous_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = data_transformation.total_categorical_features(dataset)\n",
    "print(\"The number of categorical variables are \", len(categorical_features))\n",
    "dataset[categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_transformation.filling_missing_values(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[categorical_features_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[numerical_features_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_variables = handling_date_time_variables(config=data_transformation_config)\n",
    "dataset = date_time_variables.transform(dataset)\n",
    "dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transform = log_transform_of_numeric_variables(config=data_transformation_config)\n",
    "dataset = log_transform.transform(dataset)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_categorical_values = handling_rare_categorical_values(config=data_transformation_config)\n",
    "dataset = rare_categorical_values.transform(dataset)\n",
    "dataset[['Condition2']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = handling_ordinal_categorical_values(config=data_transformation_config)\n",
    "ordinal_features.fit(dataset)\n",
    "dataset = ordinal_features.transform(dataset)\n",
    "dataset[data_transformation_config.params_ordinal_categorical_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = handling_nominal_categorical_values(config=data_transformation_config)\n",
    "nominal_features.fit(dataset)\n",
    "dataset = nominal_features.transform(dataset)\n",
    "dataset[data_transformation_config.params_nominal_categorical_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Removal_of_outlier = handling_outliers_for_continous_variable(config=data_transformation_config)\n",
    "Removal_of_outlier.fit(dataset)\n",
    "print(Removal_of_outlier.iqr_boundaries_conitnous_feature)\n",
    "dataset = Removal_of_outlier.transform(dataset)\n",
    "dataset[continuous_feature].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\transformed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features: 23\n",
      "Index(['MSSubClass', 'LotArea', 'Neighborhood', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF',\n",
      "       'TotalBsmtSF', 'HeatingQC', '1stFlrSF', 'GrLivArea', 'BsmtFullBath',\n",
      "       'KitchenQual', 'TotRmsAbvGrd', 'Fireplaces', 'FireplaceQu',\n",
      "       'GarageYrBlt', 'GarageCars', 'WoodDeckSF', 'OpenPorchSF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X = dataset1.drop(['Id','SalePrice'],axis=1)\n",
    "Y = dataset1[['SalePrice']]\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X, Y)\n",
    "selected_feat = X.columns[(feature_sel_model.get_support())]\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9.041922</td>\n",
       "      <td>12.163641</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.559615</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>...</td>\n",
       "      <td>7.444249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.169518</td>\n",
       "      <td>12.101696</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.885510</td>\n",
       "      <td>5.648974</td>\n",
       "      <td>...</td>\n",
       "      <td>7.140453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.697093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9.328123</td>\n",
       "      <td>12.163641</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.186209</td>\n",
       "      <td>6.073045</td>\n",
       "      <td>...</td>\n",
       "      <td>7.487734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.737670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>9.164296</td>\n",
       "      <td>12.206659</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.375278</td>\n",
       "      <td>6.291569</td>\n",
       "      <td>...</td>\n",
       "      <td>7.448334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.555348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9.565214</td>\n",
       "      <td>12.676000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.484635</td>\n",
       "      <td>6.194405</td>\n",
       "      <td>...</td>\n",
       "      <td>7.695303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.257495</td>\n",
       "      <td>4.430817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass   LotArea  Neighborhood  OverallQual  OverallCond  YearBuilt  \\\n",
       "0        60.0  9.041922     12.163641          7.0          5.0        5.0   \n",
       "1        20.0  9.169518     12.101696          6.0          8.0       31.0   \n",
       "2        60.0  9.328123     12.163641          7.0          5.0        7.0   \n",
       "3        70.0  9.164296     12.206659          7.0          5.0       91.0   \n",
       "4        60.0  9.565214     12.676000          8.0          5.0        8.0   \n",
       "\n",
       "   YearRemodAdd  BsmtFinType1  BsmtFinSF1  BsmtUnfSF  ...  GrLivArea  \\\n",
       "0           5.0             6    6.559615   5.010635  ...   7.444249   \n",
       "1          31.0             4    6.885510   5.648974  ...   7.140453   \n",
       "2           6.0             6    6.186209   6.073045  ...   7.487734   \n",
       "3          36.0             4    5.375278   6.291569  ...   7.448334   \n",
       "4           8.0             6    6.484635   6.194405  ...   7.695303   \n",
       "\n",
       "   BsmtFullBath  KitchenQual  TotRmsAbvGrd  Fireplaces  FireplaceQu  \\\n",
       "0           1.0            2           8.0         0.0            1   \n",
       "1           0.0            1           6.0         1.0            3   \n",
       "2           1.0            2           6.0         1.0            3   \n",
       "3           1.0            2           7.0         1.0            4   \n",
       "4           1.0            2           9.0         1.0            3   \n",
       "\n",
       "   GarageYrBlt  GarageCars  WoodDeckSF  OpenPorchSF  \n",
       "0          5.0         2.0    0.000000     4.110874  \n",
       "1         31.0         2.0    5.697093     0.000000  \n",
       "2          7.0         2.0    0.000000     3.737670  \n",
       "3          8.0         3.0    0.000000     3.555348  \n",
       "4          8.0         3.0    5.257495     4.430817  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected =X[selected_feat]\n",
    "X_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1314, 23), (146, 23))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_selected,Y,test_size=0.1,random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_copy = X_train.copy()\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_copy)\n",
    "X_train_data = pd.DataFrame(scaler.transform(X_copy), columns=selected_feat)\n",
    "X_test_data = pd.DataFrame(scaler.transform(X_test), columns=selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\harik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8915319920524694, 0.8890182559450004, 0.8094233922369708, 0.8805981099194479, 0.8929473424376737, 0.7496123295499876]\n",
      "[0.8710831053082628, 0.8680954681313529, 0.7734950153636129, 0.8580879175272127, 0.8727652840447762, 0.7024080965962967]\n",
      "[0.014852771905645037, 0.015196983528423996, 0.02609608989062562, 0.016349973342621123, 0.014658964746872692, 0.03428615522264247]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "list_of_models = ['Linear Regression', 'Ridge Regression', 'Polynomial Regression', 'SVR', 'Random Forrest Regressor', 'Decision Tree Regressor' ]\n",
    "r2_score_of_models=[]\n",
    "adjusted_r2_score =[]\n",
    "mse=[]\n",
    "for i  in list_of_models:\n",
    "    if i == 'Linear Regression':\n",
    "        model = LinearRegression()\n",
    "    elif i == 'Ridge Regression':\n",
    "        model = Ridge()\n",
    "    elif i == 'Polynomial Regression':\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear_model', LinearRegression())])\n",
    "    elif i == 'SVR':\n",
    "        model = SVR(kernel='rbf', C=1.0)\n",
    "    elif i == 'Random Forrest Regressor':\n",
    "        model = RandomForestRegressor(n_estimators=100)\n",
    "    else:\n",
    "        model = DecisionTreeRegressor(max_depth=5)\n",
    "# Train the model on the training data\n",
    "\n",
    "    model.fit(X_train_data, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "\n",
    "    y_pred = model.predict(X_test_data)\n",
    "\n",
    "# Evaluate the model performance (e.g., R-squared, Mean Squared Error)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_score_of_models.append(r2)\n",
    "\n",
    "# Calculate the adjusted R²\n",
    "\n",
    "    n = X_test_data.shape[0]  # Number of observations (samples) in the testing set\n",
    "    p = X_test_data.shape[1]  # Number of features in the model\n",
    "    adjusted_r2_score.append(1 - (1 - r2) * (n - 1) / (n - p - 1))\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score_of_models)\n",
    "print(adjusted_r2_score)\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted_R2_Score</th>\n",
       "      <th>R2_Score</th>\n",
       "      <th>Mean_Squared_Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.871083</td>\n",
       "      <td>0.891532</td>\n",
       "      <td>0.014853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.868095</td>\n",
       "      <td>0.889018</td>\n",
       "      <td>0.015197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Regression</th>\n",
       "      <td>0.773495</td>\n",
       "      <td>0.809423</td>\n",
       "      <td>0.026096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.858088</td>\n",
       "      <td>0.880598</td>\n",
       "      <td>0.016350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forrest Regressor</th>\n",
       "      <td>0.872765</td>\n",
       "      <td>0.892947</td>\n",
       "      <td>0.014659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <td>0.702408</td>\n",
       "      <td>0.749612</td>\n",
       "      <td>0.034286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Adjusted_R2_Score  R2_Score  Mean_Squared_Error\n",
       "Models                                                                   \n",
       "Linear Regression                  0.871083  0.891532            0.014853\n",
       "Ridge Regression                   0.868095  0.889018            0.015197\n",
       "Polynomial Regression              0.773495  0.809423            0.026096\n",
       "SVR                                0.858088  0.880598            0.016350\n",
       "Random Forrest Regressor           0.872765  0.892947            0.014659\n",
       "Decision Tree Regressor            0.702408  0.749612            0.034286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Models': list_of_models, 'Adjusted_R2_Score': adjusted_r2_score, 'R2_Score': r2_score_of_models , 'Mean_Squared_Error': mse}\n",
    "performance_metrics = pd.DataFrame.from_dict(data)\n",
    "performance_metrics.set_index('Models', inplace = True)\n",
    "performance_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
