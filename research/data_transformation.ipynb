{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\harik\\\\OneDrive\\\\Desktop\\\\HARIKRISHNAN_DETAILS\\\\Real_Estate_Predictor_Web_App\\\\Real_Estate_Price_Predictor_Web_App'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir:Path\n",
    "    data_file:Path\n",
    "    transformed_data:Path\n",
    "    date_time_handler_model_file:Path\n",
    "    log_transformer_model_file:Path\n",
    "    ordinal_encoder_model_file: Path\n",
    "    nominal_encoder_model_file: Path\n",
    "    remove_outlier_model_file: Path\n",
    "    rare_categorical_handler_file: Path\n",
    "    params_discrete_feature: list\n",
    "    params_Id_column: list\n",
    "    params_categorical_stratergy:str\n",
    "    params_numerical_stratergy:str\n",
    "    params_fill_value:str\n",
    "    params_target_label:str\n",
    "    params_rare_categorical_variable:str\n",
    "    params_ordinal_categorical_feature:list\n",
    "    params_nominal_categorical_feature:list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PredictConfig:\n",
    "    date_time_handler_model_file: Path\n",
    "    log_transformer_model_file: Path\n",
    "    ordinal_encoder_model_file: Path\n",
    "    nominal_encoder_model_file: Path\n",
    "    rare_categorical_handler_file: Path\n",
    "    remove_outlier_model_file: Path\n",
    "    feature_scaling_model: Path\n",
    "    best_model_directory: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_estate_price_predictor.constants import *\n",
    "from real_estate_price_predictor.utils.common import read_yaml, create_directories, save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_file = config.data_file,\n",
    "            transformed_data = config.transformed_data_file,\n",
    "            date_time_handler_model_file = config.date_time_handler_model_file,\n",
    "            log_transformer_model_file = config.log_transformer_model_file,\n",
    "            ordinal_encoder_model_file = config.ordinal_encoder_model_file,\n",
    "            nominal_encoder_model_file =  config.nominal_encoder_model_file,\n",
    "            remove_outlier_model_file = config.remove_outlier_model_file,\n",
    "            rare_categorical_handler_file = config.rare_categorical_handler_file,\n",
    "            params_discrete_feature = self.params.discrete_feature,\n",
    "            params_Id_column = self.params.Id_column,\n",
    "            params_categorical_stratergy = self.params.categorical_stratergy,\n",
    "            params_numerical_stratergy = self.params.numerical_stratergy,\n",
    "            params_fill_value = self.params.fill_value,\n",
    "            params_target_label = self.params.target_label,\n",
    "            params_rare_categorical_variable = self.params.rare_categorical_variable,\n",
    "            params_ordinal_categorical_feature = self.params.ordinal_categorical_feature,\n",
    "            params_nominal_categorical_feature = self.params.nominal_categorical_feature\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "    \n",
    "    def get_predict_config(self) -> PredictConfig:\n",
    "        config = self.config.predict\n",
    "\n",
    "        predict_config = PredictConfig(\n",
    "            date_time_handler_model_file = config.date_time_handler_model_file ,\n",
    "            log_transformer_model_file = config.log_transformer_model_file,\n",
    "            ordinal_encoder_model_file = config.ordinal_encoder_model_file,\n",
    "            nominal_encoder_model_file = config.nominal_encoder_model_file,\n",
    "            rare_categorical_handler_file = config.rare_categorical_handler_file,\n",
    "            remove_outlier_model_file = config.remove_outlier_model_file,\n",
    "            feature_scaling_model = config.feature_scaling_model,\n",
    "            best_model_directory = config.best_model_directory\n",
    "        )\n",
    "\n",
    "        return predict_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparatingDifferentFeatures:\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def read_data(self):\n",
    "        dataset = pd.read_csv(self.config.data_file)\n",
    "        return dataset\n",
    "\n",
    "# Features with null values\n",
    "\n",
    "    def features_with_null_values(self, df:pd.DataFrame):\n",
    "        dataset = df\n",
    "        features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n",
    "        return features_with_na\n",
    "    \n",
    "# Finding both numerical and categorical features with null values\n",
    "\n",
    "    def num_and_categorical_features_with_na(self,df:pd.DataFrame, categorical:bool):\n",
    "        numerical_features_with_na =[]\n",
    "        categorical_features_with_na =[]\n",
    "        features_with_na = self.features_with_null_values(df)\n",
    "        for feature in features_with_na:\n",
    "            if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "                numerical_features_with_na.append(feature)\n",
    "            else:\n",
    "                categorical_features_with_na.append(feature)\n",
    "        if categorical:\n",
    "            return categorical_features_with_na\n",
    "        else: \n",
    "            return numerical_features_with_na\n",
    "    \n",
    "# Finding all the numerical features\n",
    "\n",
    "    def total_numerical_features(self,dataset:pd.DataFrame):\n",
    "        numerical_features = []\n",
    "        for feature in dataset.columns:\n",
    "            if dataset[feature].dtypes != 'O':\n",
    "                numerical_features.append(feature)\n",
    "        return numerical_features\n",
    "\n",
    "# Finding year or datatime variable\n",
    "\n",
    "    def finding_year_feature(self,dataset:pd.DataFrame):\n",
    "        year_feature = []\n",
    "        numerical_features = self.total_numerical_features(dataset)\n",
    "        for feature in numerical_features:\n",
    "            if 'Yr' in feature or 'Year' in feature:\n",
    "                year_feature.append(feature)\n",
    "        return year_feature\n",
    "        \n",
    "# Finding Continuous Variable\n",
    "\n",
    "    def continous_variables(self,df:pd.DataFrame):\n",
    "        continuous_feature=[]\n",
    "        numerical_features = self.total_numerical_features(df) \n",
    "        year_feature = self.finding_year_feature(df)\n",
    "        for feature in numerical_features:\n",
    "            if feature not in self.config.params_discrete_feature+year_feature+self.config.params_Id_column:\n",
    "                continuous_feature.append(feature)\n",
    "        return continuous_feature\n",
    "\n",
    "# Replacing the zeros with 1 to perform log transform\n",
    "\n",
    "    def replacing_zeros_of_continuous_features(self,dataset:pd.DataFrame):\n",
    "        continuous_feature = self.continous_variables(dataset)\n",
    "        for feature in continuous_feature:\n",
    "            dataset.loc[dataset[feature] == 0, feature] = 1\n",
    "        return dataset\n",
    "\n",
    "# Finding the categorical features\n",
    "\n",
    "    def total_categorical_features(self,dataset:pd.DataFrame):\n",
    "        return [feature for feature in dataset.columns if dataset[feature].dtypes=='O']\n",
    "\n",
    "# Handling Missing Values by creating a new category for categroical and with median for numerical\n",
    "\n",
    "    def filling_missing_values(self, dataset:pd.DataFrame):\n",
    "        categorical_imputer = SimpleImputer(strategy= self.config.params_categorical_stratergy,fill_value=self.config.params_fill_value)\n",
    "        numerical_imputer = SimpleImputer(strategy=self.config.params_numerical_stratergy)\n",
    "        categorical_features = self.total_categorical_features(dataset)\n",
    "        numerical_features = self.total_numerical_features(dataset)\n",
    "        dataset[categorical_features] = categorical_imputer.fit_transform(dataset[categorical_features])\n",
    "        dataset[numerical_features] = numerical_imputer.fit_transform(dataset[numerical_features])\n",
    "        # save_object(self.config.categorical_imputer_model_file,categorical_imputer)\n",
    "        # save_object(self.config.numerical_imputer_model_file,numerical_imputer)\n",
    "        return dataset\n",
    "    \n",
    "# Saving the transformed data\n",
    "\n",
    "    def save_the_transformed_data(self,dataset:pd.DataFrame):\n",
    "        dataset.to_csv(self.config.transformed_data)\n",
    "\n",
    "    def save_the_model(self,dict_of_transform_models:dict):\n",
    "        for key in dict_of_transform_models.keys():\n",
    "            if key == 'date_time_variables':\n",
    "                save_object(self.config.date_time_handler_model_file,dict_of_transform_models[key])\n",
    "            elif key == 'log_transformer':\n",
    "                save_object(self.config.log_transformer_model_file,dict_of_transform_models[key])\n",
    "            elif key == 'rare_categorical_values_handler':\n",
    "                save_object(self.config.rare_categorical_handler_file,dict_of_transform_models[key])\n",
    "            elif key == 'ordinal_encoder':\n",
    "                save_object(self.config.ordinal_encoder_model_file,dict_of_transform_models[key])\n",
    "            elif key == 'nominal_encoder': \n",
    "                save_object(self.config.nominal_encoder_model_file,dict_of_transform_models[key])\n",
    "            elif key == 'remove_outliers_transformer':\n",
    "                save_object(self.config.remove_outlier_model_file,dict_of_transform_models[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_date_time_variables(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs \n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "         year_features = self.finding_year_feature(X)\n",
    "         for feature in year_features:\n",
    "             if feature != 'YrSold':\n",
    "                 X[feature]=X['YrSold']-X[feature]\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_transform_of_numeric_variables(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self, config:DataTransformationConfig): # no *args or **kargs\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "         continous_features = self.continous_variables(X)\n",
    "         X = self.replacing_zeros_of_continuous_features(X)\n",
    "         for feature in continous_features:\n",
    "             X[feature]=np.log(X[feature])\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_rare_categorical_values(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs\n",
    "         super().__init__(config)\n",
    "         self.temp_df_dict={}\n",
    "    def fit(self, X, y=None):\n",
    "         categorical_features = self.total_categorical_features(X)\n",
    "         for feature in categorical_features:\n",
    "             temp=X.groupby(feature)[self.config.params_target_label].count()/len(X)\n",
    "             temp_df=temp[temp>0.01].index\n",
    "             self.temp_df_dict[feature]= temp_df\n",
    "         return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "         categorical_features = self.total_categorical_features(X)\n",
    "         for feature in categorical_features:\n",
    "             X[feature]=np.where(X[feature].isin(self.temp_df_dict[feature]),X[feature],self.config.params_rare_categorical_variable)\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_ordinal_categorical_values(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs\n",
    "         self.label_ordered_feature ={}\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         for feature in self.config.params_ordinal_categorical_feature:\n",
    "             labels_ordered=X.groupby([feature])[self.config.params_target_label].mean().sort_values().index\n",
    "             labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n",
    "             self.label_ordered_feature[feature] = labels_ordered\n",
    "         return self\n",
    "    def transform(self, X:pd.DataFrame, y=None):\n",
    "         for feature in self.config.params_ordinal_categorical_feature:\n",
    "           if feature in X.columns:\n",
    "               X[feature]=X[feature].map(self.label_ordered_feature[feature])\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_nominal_categorical_values(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig): # no *args or **kargs\n",
    "         self.label_nominal_feature ={}\n",
    "         super().__init__(config)\n",
    "    def fit(self, X, y=None):\n",
    "         for feature in self.config.params_nominal_categorical_feature:\n",
    "             nominal_label=X.groupby([feature])[self.config.params_target_label].mean().to_dict()\n",
    "             self.label_nominal_feature[feature] = nominal_label\n",
    "         return self\n",
    "    def transform(self, X:pd.DataFrame, y=None):\n",
    "         for feature in self.config.params_nominal_categorical_feature:\n",
    "           if feature in X.columns:\n",
    "               X[feature]=X[feature].map(self.label_nominal_feature[feature])\n",
    "         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handling_outliers_for_continous_variable(BaseEstimator, TransformerMixin,SeparatingDifferentFeatures):\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.iqr_boundaries_conitnous_feature ={}\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        continuous_feature = self.continous_variables(X)\n",
    "        for feature in continuous_feature:\n",
    "            IQR=X[feature].quantile(0.75)-X[feature].quantile(0.25)\n",
    "            lower_bridge=X[feature].quantile(0.25)-(IQR*3)\n",
    "            upper_bridge=X[feature].quantile(0.75)+(IQR*3)\n",
    "            self.iqr_boundaries_conitnous_feature[feature] = [lower_bridge,upper_bridge]\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        continuous_feature = self.continous_variables(X)\n",
    "        for feature in continuous_feature:\n",
    "            lower_bridge, upper_bridge = self.iqr_boundaries_conitnous_feature[feature]\n",
    "            X.loc[X[feature]<=lower_bridge,feature]=lower_bridge\n",
    "            X.loc[X[feature]>=upper_bridge,feature]=upper_bridge\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = SeparatingDifferentFeatures(config=data_transformation_config)\n",
    "\n",
    "    # Read the data\n",
    "\n",
    "    dataset = data_transformation.read_data()\n",
    "\n",
    "    # Handling Null Values\n",
    "\n",
    "    dataset = data_transformation.filling_missing_values(dataset)\n",
    "\n",
    "    # Handling date time variables\n",
    "\n",
    "    date_time_variables = handling_date_time_variables(config=data_transformation_config)\n",
    "    dataset = date_time_variables.transform(dataset)\n",
    "\n",
    "    # Transforming the continous variables using logrithmic transform\n",
    "\n",
    "    log_transform = log_transform_of_numeric_variables(config=data_transformation_config)\n",
    "    dataset = log_transform.transform(dataset)\n",
    "\n",
    "    # Handling rare categorical variable\n",
    "\n",
    "    rare_categorical_values = handling_rare_categorical_values(config=data_transformation_config)\n",
    "    rare_categorical_values.fit(dataset)\n",
    "    dataset = rare_categorical_values.transform(dataset)    \n",
    "\n",
    "    # Encoding the ordinal categorical features using (Target Guided Encoding)\n",
    "\n",
    "    ordinal_features = handling_ordinal_categorical_values(config=data_transformation_config)\n",
    "    ordinal_features.fit(dataset)\n",
    "    dataset = ordinal_features.transform(dataset)\n",
    "\n",
    "    # Encoding the nominal categorical features using (Mean Encoding)\n",
    "\n",
    "    nominal_features = handling_nominal_categorical_values(config=data_transformation_config)\n",
    "    nominal_features.fit(dataset)\n",
    "    dataset = nominal_features.transform(dataset)    \n",
    "\n",
    "    # Removing the Outliers in Continous feature\n",
    "\n",
    "    Removal_of_outlier = handling_outliers_for_continous_variable(config=data_transformation_config)\n",
    "    Removal_of_outlier.fit(dataset)\n",
    "    dataset = Removal_of_outlier.transform(dataset)\n",
    "\n",
    "    # Saving the transformed data\n",
    "\n",
    "    data_transformation.save_the_transformed_data(dataset)\n",
    "\n",
    "    # Saving the models:\n",
    "\n",
    "    dict_of_preporcessing_models ={\n",
    "                               'rare_categorical_values_handler':rare_categorical_values,\n",
    "                               'date_time_variables': date_time_variables,\n",
    "                               'log_transformer': log_transform,\n",
    "                               'ordinal_encoder':ordinal_features,\n",
    "                               'nominal_encoder':nominal_features,\n",
    "                               'remove_outliers_transformer':Removal_of_outlier}\n",
    "    data_transformation.save_the_model(dict_of_preporcessing_models)\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigurationManager()\n",
    "data_transformation_config = config.get_data_transformation_config()\n",
    "data_transformation = SeparatingDifferentFeatures(config=data_transformation_config)\n",
    "dataset = data_transformation.read_data()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_with_na = data_transformation.num_and_categorical_features_with_na(dataset,True)\n",
    "numerical_features_with_na = data_transformation.num_and_categorical_features_with_na(dataset,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The categrical null count is \",len(categorical_features_with_na))\n",
    "print(\"The numerical null count is \",len(numerical_features_with_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data_transformation.total_numerical_features(dataset)\n",
    "print('Number of numerical variables: ', len(numerical_features))\n",
    "dataset[numerical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature = data_transformation.continous_variables(dataset)\n",
    "print(\"Continuous feature Count {}\".format(len(continuous_feature)))\n",
    "dataset[continuous_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = data_transformation.total_categorical_features(dataset)\n",
    "print(\"The number of categorical variables are \", len(categorical_features))\n",
    "dataset[categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_transformation.filling_missing_values(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[categorical_features_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[numerical_features_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_variables = handling_date_time_variables(config=data_transformation_config)\n",
    "dataset = date_time_variables.transform(dataset)\n",
    "dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transform = log_transform_of_numeric_variables(config=data_transformation_config)\n",
    "dataset = log_transform.transform(dataset)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_categorical_values = handling_rare_categorical_values(config=data_transformation_config)\n",
    "rare_categorical_values.fit(dataset)\n",
    "dataset = rare_categorical_values.transform(dataset)\n",
    "dataset[['Condition2']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = handling_ordinal_categorical_values(config=data_transformation_config)\n",
    "ordinal_features.fit(dataset)\n",
    "dataset = ordinal_features.transform(dataset)\n",
    "dataset[data_transformation_config.params_ordinal_categorical_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = handling_nominal_categorical_values(config=data_transformation_config)\n",
    "nominal_features.fit(dataset)\n",
    "dataset = nominal_features.transform(dataset)\n",
    "dataset[data_transformation_config.params_nominal_categorical_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Removal_of_outlier = handling_outliers_for_continous_variable(config=data_transformation_config)\n",
    "Removal_of_outlier.fit(dataset)\n",
    "print(Removal_of_outlier.iqr_boundaries_conitnous_feature)\n",
    "dataset = Removal_of_outlier.transform(dataset)\n",
    "dataset[continuous_feature].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\transformed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X = dataset1.drop(['Id','SalePrice'],axis=1)\n",
    "Y = dataset1[['SalePrice']]\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X, Y)\n",
    "selected_feat = X.columns[(feature_sel_model.get_support())]\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected =X[selected_feat]\n",
    "X_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_selected,Y,test_size=0.1,random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_copy = X_train.copy()\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_copy)\n",
    "X_train_data = pd.DataFrame(scaler.transform(X_copy), columns=selected_feat)\n",
    "X_test_data = pd.DataFrame(scaler.transform(X_test), columns=selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "list_of_models = ['Linear Regression', 'Ridge Regression', 'Polynomial Regression', 'SVR', 'Random Forrest Regressor', 'Decision Tree Regressor' ]\n",
    "r2_score_of_models=[]\n",
    "adjusted_r2_score =[]\n",
    "mse=[]\n",
    "for i  in list_of_models:\n",
    "    if i == 'Linear Regression':\n",
    "        model = LinearRegression()\n",
    "    elif i == 'Ridge Regression':\n",
    "        model = Ridge()\n",
    "    elif i == 'Polynomial Regression':\n",
    "        model = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear_model', LinearRegression())])\n",
    "    elif i == 'SVR':\n",
    "        model = SVR(kernel='rbf', C=1.0)\n",
    "    elif i == 'Random Forrest Regressor':\n",
    "        model = RandomForestRegressor(n_estimators=100)\n",
    "    else:\n",
    "        model = DecisionTreeRegressor(max_depth=5)\n",
    "# Train the model on the training data\n",
    "\n",
    "    model.fit(X_train_data, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "\n",
    "    y_pred = model.predict(X_test_data)\n",
    "\n",
    "# Evaluate the model performance (e.g., R-squared, Mean Squared Error)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_score_of_models.append(r2)\n",
    "\n",
    "# Calculate the adjusted R²\n",
    "\n",
    "    n = X_test_data.shape[0]  # Number of observations (samples) in the testing set\n",
    "    p = X_test_data.shape[1]  # Number of features in the model\n",
    "    adjusted_r2_score.append(1 - (1 - r2) * (n - 1) / (n - p - 1))\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score_of_models)\n",
    "print(adjusted_r2_score)\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Models': list_of_models, 'Adjusted_R2_Score': adjusted_r2_score, 'R2_Score': r2_score_of_models , 'Mean_Squared_Error': mse}\n",
    "performance_metrics = pd.DataFrame.from_dict(data)\n",
    "performance_metrics.set_index('Models', inplace = True)\n",
    "performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = pd.read_csv(r\"C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\DATA SCIENCE\\ADVANCE_HOUSE_PRICE_PREDICTION\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = ['MSSubClass', 'LotArea', 'Neighborhood', 'OverallQual', 'OverallCond',\n",
    " 'YearBuilt', 'YearRemodAdd', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF',\n",
    " 'TotalBsmtSF', 'HeatingQC', '1stFlrSF', 'GrLivArea', 'BsmtFullBath',\n",
    " 'KitchenQual', 'TotRmsAbvGrd', 'Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
    " 'GarageCars', 'WoodDeckSF', 'OpenPorchSF','YrSold' ]\n",
    "# features = np.append(features,'YrSold')\n",
    "print(features,len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-08 23:16:31,385: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-10-08 23:16:31,399: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-10-08 23:16:31,401: INFO: common: created directory at: artifacts]\n",
      "[2024-10-08 23:16:31,403: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    }
   ],
   "source": [
    "X_final = pd.read_csv(r\"C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\DATA SCIENCE\\ADVANCE_HOUSE_PRICE_PREDICTION\\test_5.csv\")\n",
    "config = ConfigurationManager()\n",
    "data_transformation_config = config.get_data_transformation_config()\n",
    "data_transformation = SeparatingDifferentFeatures(config=data_transformation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categrical null count is  0\n",
      "The numerical null count is  0\n",
      "Number of numerical variables:  19\n",
      "The number of categorical variables are  5\n"
     ]
    }
   ],
   "source": [
    "categorical_features_with_na_final = data_transformation.num_and_categorical_features_with_na(X_final,True)\n",
    "numerical_features_with_na_final = data_transformation.num_and_categorical_features_with_na(X_final,False)\n",
    "print(\"The categrical null count is \",len(categorical_features_with_na_final))\n",
    "print(\"The numerical null count is \",len(numerical_features_with_na_final))\n",
    "numerical_features_final = data_transformation.total_numerical_features(X_final)\n",
    "print('Number of numerical variables: ', len(numerical_features_final))\n",
    "X_final[numerical_features_final].head()\n",
    "categorical_features_final = data_transformation.total_categorical_features(X_final)\n",
    "print(\"The number of categorical variables are \", len(categorical_features_final))\n",
    "continuous_feature_final = data_transformation.continous_variables(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'BsmtFullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'WoodDeckSF', 'OpenPorchSF', 'YrSold']\n",
      "['Neighborhood', 'BsmtFinType1', 'HeatingQC', 'KitchenQual', 'FireplaceQu']\n",
      "['LotArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'WoodDeckSF', 'OpenPorchSF']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_features_final)\n",
    "print(categorical_features_final)\n",
    "print(continuous_feature_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_with_na_final = data_transformation.num_and_categorical_features_with_na(X_final,True)\n",
    "numerical_features_with_na_final = data_transformation.num_and_categorical_features_with_na(X_final,False)\n",
    "print(\"The categrical null count is \",len(categorical_features_with_na_final))\n",
    "print(\"The numerical null count is \",len(numerical_features_with_na_final))\n",
    "numerical_features_final = data_transformation.total_numerical_features(X_final)\n",
    "print('Number of numerical variables: ', len(numerical_features_final))\n",
    "X_final[numerical_features_final].head()\n",
    "categorical_features_final = data_transformation.total_categorical_features(X_final)\n",
    "print(\"The number of categorical variables are \", len(categorical_features_final))\n",
    "X_final[categorical_features_final].head()\n",
    "X_final = data_transformation.filling_missing_values(X_final)\n",
    "X_final[categorical_features_with_na_final].isnull().sum()\n",
    "X_final[numerical_features_with_na_final].isnull().sum()\n",
    "X_final = date_time_variables.transform(X_final)\n",
    "X_final[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()\n",
    "X_final = log_transform.transform(X_final)\n",
    "X_final.head()\n",
    "X_final = rare_categorical_values.transform(X_final)\n",
    "X_final = ordinal_features.transform(X_final)\n",
    "dataset[data_transformation_config.params_ordinal_categorical_feature].head()\n",
    "X_final = nominal_features.transform(X_final)\n",
    "dataset[data_transformation_config.params_nominal_categorical_feature].head()\n",
    "X_final = Removal_of_outlier.transform(X_final)\n",
    "X_final[continuous_feature_final].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_object(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file_obj:\n",
    "            return pickle.load(file_obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = data_transformation.filling_missing_values(X_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>11622.0</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>others</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotArea Neighborhood  OverallQual  OverallCond  YearBuilt  \\\n",
       "0        20.0  11622.0        NAmes          5.0          6.0     1961.0   \n",
       "\n",
       "   YearRemodAdd BsmtFinType1  BsmtFinSF1  BsmtUnfSF  ...  BsmtFullBath  \\\n",
       "0        1961.0          Rec       468.0      270.0  ...           0.0   \n",
       "\n",
       "  KitchenQual  TotRmsAbvGrd  Fireplaces  FireplaceQu GarageYrBlt  GarageCars  \\\n",
       "0          TA           5.0         0.0       others      1961.0         1.0   \n",
       "\n",
       "   WoodDeckSF OpenPorchSF  YrSold  \n",
       "0       140.0         0.0  2010.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = X_final.head(1)\n",
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_transformer = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\date_time_handler.pkl')\n",
    "log_transformer = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\log_transfomer.pkl')\n",
    "rare_categorical_model = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\rare_categorical_model.pkl')\n",
    "ordinal_encoder = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\ordinal_encoder_model.pkl')\n",
    "nominal_encoder = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\nominal_encoder_model.pkl')\n",
    "remove_outlier_model = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\data_transformation\\remove_outlier_model.pkl')\n",
    "feature_scaler = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\train_test_data_scaled\\min_max_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = date_time_transformer.transform(X_final)\n",
    "X_final = log_transformer.transform(X_final)\n",
    "X_final = rare_categorical_model.transform(X_final)\n",
    "X_final = ordinal_encoder.transform(X_final)\n",
    "X_final = nominal_encoder.transform(X_final)\n",
    "X_final = remove_outlier_model.transform(X_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.drop(['YrSold'],axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = ['MSSubClass', 'LotArea', 'Neighborhood', 'OverallQual', 'OverallCond',\n",
    " 'YearBuilt', 'YearRemodAdd', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtUnfSF',\n",
    " 'TotalBsmtSF', 'HeatingQC', '1stFlrSF', 'GrLivArea', 'BsmtFullBath',\n",
    " 'KitchenQual', 'TotRmsAbvGrd', 'Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
    " 'GarageCars', 'WoodDeckSF', 'OpenPorchSF']\n",
    "X_final = X_final[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.DataFrame(feature_scaler.transform(X_final), columns=X_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_object(r'C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\artifacts\\model_trainer\\HyperParameterRandomnForrestRegression.pkl')\n",
    "y_pred = model.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.exp(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.exp(11.70983481))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    \n",
    "    def __init__(self, config = PredictConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def predict(self,dataframe:pd.DataFrame):\n",
    "        date_time_transformer = load_object(self.config.date_time_handler_model_file)\n",
    "        log_transformer = load_object(self.config.log_transformer_model_file)\n",
    "        rare_categorical_model = load_object(self.config.rare_categorical_handler_file)\n",
    "        ordinal_encoder = load_object(self.config.ordinal_encoder_model_file)\n",
    "        nominal_encoder = load_object(self.config.nominal_encoder_model_file)\n",
    "        remove_outlier_model = load_object(self.config.remove_outlier_model_file)\n",
    "        feature_scaler = load_object(self.config.feature_scaling_model)\n",
    "        for i in os.listdir(self.config.best_model_directory):\n",
    "            if i.__contains__('pkl'):\n",
    "                model_name = i\n",
    "        model = load_object(os.path.join(self.config.best_model_directory,model_name))\n",
    "        dataframe = date_time_transformer.transform(dataframe)\n",
    "        dataframe = log_transformer.transform(dataframe)\n",
    "        dataframe = rare_categorical_model.transform(dataframe)\n",
    "        dataframe = ordinal_encoder.transform(dataframe)\n",
    "        dataframe = nominal_encoder.transform(dataframe)\n",
    "        dataframe = remove_outlier_model.transform(dataframe)\n",
    "        dataframe.drop(['YrSold'],axis=1,inplace= True)\n",
    "        dataframe = pd.DataFrame(feature_scaler.transform(dataframe), columns=dataframe.columns)\n",
    "        y_pred = model.predict(dataframe)\n",
    "        return np.exp(y_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-08 23:17:16,452: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-10-08 23:17:16,465: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-10-08 23:17:16,468: INFO: common: created directory at: artifacts]\n",
      "122485.91779489782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=X['YrSold']-X[feature]\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=np.log(X[feature])\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:162: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=np.where(X[feature].isin(self.temp_df_dict[feature]),X[feature],self.config.params_rare_categorical_variable)\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=X[feature].map(self.label_ordered_feature[feature])\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=X[feature].map(self.label_ordered_feature[feature])\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=X[feature].map(self.label_ordered_feature[feature])\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=X[feature].map(self.label_ordered_feature[feature])\n",
      "C:\\Users\\harik\\OneDrive\\Desktop\\HARIKRISHNAN_DETAILS\\Real_Estate_Predictor_Web_App\\Real_Estate_Price_Predictor_Web_App\\src\\real_estate_price_predictor\\components\\data_transformation.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature]=X[feature].map(self.label_nominal_feature[feature])\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_160300\\3462854247.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.drop(['YrSold'],axis=1,inplace= True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    predict_config = config.get_predict_config()\n",
    "    predict = Predict(config=predict_config)\n",
    "    result = predict.predict(X_1)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(123132.04830711319)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
